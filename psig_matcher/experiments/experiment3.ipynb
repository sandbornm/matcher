{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Monte Carlo Sampling Consistency\n",
    "\n",
    "This notebook will contain gathered results from experiment 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Sampling Consistency\n",
    "## Methodlogy\n",
    "For each part type, run the entire experiment 100 times, tracking the convergence of the Monte Carlo Sampling for each run. Repeat this for a few different hyperparamter values.\n",
    "## Deliverables\n",
    "For each part type, how consistent is the final Monte Carlo approximation of collision? How consistent is the convergence process of said sampling? (Something like time-series comparision: Euclidean distance, ect). What does this tell us about the process? Is the consistency affected by the hyperparamters or part type? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "Installing required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Directory to Parent to allow importing external data files. Please change the specified path based on where this repo exists for you locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/GitHub/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "import dataclasses\n",
    "import argparse\n",
    "import sys\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "@dataclass\n",
    "class NormalDistribution:\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "@dataclass\n",
    "class Part:\n",
    "\n",
    "    type: str\n",
    "    sub_part_name: str\n",
    "    sensor: str\n",
    "    signals: List   # Signal is numpy array of (500,3) with [frequency, Z, X]\n",
    "\n",
    "\n",
    "def load_part_data(part_type: str) -> List[Part]:\n",
    "\n",
    "    parts = []\n",
    "    for part_dir in os.listdir(f'psig_matcher/data/{part_type}'):\n",
    "\n",
    "        sensor = part_dir[1:]\n",
    "        measurement_files = glob.glob(f'psig_matcher/data/{part_type}/{part_dir}/*.npy')\n",
    "        measurements = [np.load(f) for f in measurement_files]\n",
    "        parts.append(Part(part_type, part_dir, sensor, measurements))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def limit_deminsionality(parts: List[Part], frequeny_indexes: List[int]) -> List[Part]:\n",
    "    \"\"\"Use only a subset of the frequencies for the analysis. This effectivley transforms the\n",
    "    500 dimension multivariant distribution to a n-dimentional distribution where n is the\n",
    "    length of the frequency_indexes.\n",
    "    Further, this assumes use of the X axis\"\"\"\n",
    "\n",
    "    return [\n",
    "        dataclasses.replace(part, signals=[[signal[index][1] for index in frequeny_indexes] for signal in part.signals])\n",
    "        for part in parts]\n",
    "\n",
    "def compute_normal_ci(x: List[float], confidence: float) -> Tuple[float, float]:\n",
    "    \"\"\"Computes the confidence interval for a given confidence bound.\"\"\"\n",
    "\n",
    "    if np.mean(x) == 0: return (0, 0)\n",
    "    \n",
    "    if len(x) < 30:\n",
    "        return st.t.interval(confidence, len(x)-1, loc=np.mean(x), scale=st.sem(x))\n",
    "    else:\n",
    "        return stats.norm.interval(confidence, loc=np.mean(x), scale=np.std(x))\n",
    "\n",
    "def estimate_normal_dist(x: List[float], confidence: float) -> NormalDistribution:\n",
    "    \"\"\"Estimate the normal distribution for the given data.\n",
    "    This is done using: https://handbook-5-1.cochrane.org/chapter_7/7_7_3_2_obtaining_standard_deviations_from_standard_errors_and.htm#:~:text=The%20standard%20deviation%20for%20each,should%20be%20replaced%20by%205.15.\n",
    "    \"\"\"\n",
    "\n",
    "    val_comp = st.t.ppf if len(x) < 30 else stats.norm.ppf\n",
    "    lower, upper = compute_normal_ci(x, confidence)\n",
    "\n",
    "    val = val_comp(confidence, len(x)-1)\n",
    "    std = np.sqrt(len(x))*(upper-lower)*val\n",
    "    return NormalDistribution(np.mean(x, axis=0), std)\n",
    "\n",
    "\n",
    "def probability_of_multivariant_point(mu: List[float], cov: List[List[float]], x: List[float]) -> float:\n",
    "\n",
    "    #https://stats.stackexchange.com/questions/331283/how-to-calculate-the-probability-of-a-data-point-belonging-to-a-multivariate-nor\n",
    "    # Double check this math\n",
    "    m_dist_x = np.dot((x-mu).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mu))\n",
    "    return 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "\n",
    "def estimate_overlap_of_set_with_sample_signals(parts: List[Part], samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float) -> float:\n",
    "    \"\"\" I believe this is the best solution out of all them. We are directly modeling the distribution/state space that\n",
    "    the signals come from, and sampling from that. This directly correlates with the CI and is intuitive. See notion for\n",
    "    more details and defense. \"\"\"\n",
    "\n",
    "    min_confidence = 1 - confidence_bound\n",
    "    signals = [\n",
    "        signal for part in parts\n",
    "        for signal in part.signals]\n",
    "\n",
    "    part_pdfs = [estimate_normal_dist(part.signals, part_pdf_ci) for part in parts]\n",
    "    sample_pdf = estimate_normal_dist(signals, meta_pdf_ci)\n",
    "    \n",
    "    state_space_samples = np.random.multivariate_normal(sample_pdf.mean, np.diag(sample_pdf.std), samples)\n",
    "\n",
    "    # using probability_of_multivariant_point no longer directly equates to false negative rate.\n",
    "    # TODO (henry): Figure out relationship between integrated pdf range and false negative rate\n",
    "    sample_confidences = [\n",
    "        [probability_of_multivariant_point(pdf.mean, np.diag(pdf.std), sample) for pdf in part_pdfs]\n",
    "        for sample in state_space_samples]\n",
    "\n",
    "    filtered_confidences = [\n",
    "        list(filter(lambda confidence: confidence >= min_confidence, sample_confidence))\n",
    "        for sample_confidence in sample_confidences]\n",
    "\n",
    "    # We're ok with up to 1 match, but every one more than that is a conflict.\n",
    "    collisions = [max(len(confidences)-1, 0) for confidences in filtered_confidences]\n",
    "    return sum(collisions)/(samples*len(part_pdfs))\n",
    "\n",
    "def run_meta_markov_multivariant_analysis(parts: List[Part], part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "    \"\"\" Runs the Monte Carlo Approximation of multivariant collision using the signal sample meta\n",
    "    pdf methodology. The Monte Carlo Approximation will continually be run until the confidence interval\n",
    "    converges and the average of the previous 10 runs is not smaller than the average of the previous 100 runs.\"\"\"\n",
    "    collisions = []\n",
    "    confidence_ranges = []\n",
    "    while True:\n",
    "\n",
    "        multivariant_parts = limit_deminsionality(parts, list(range(part_dim)))\n",
    "        collision_rate = estimate_overlap_of_set_with_sample_signals(multivariant_parts, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n",
    "\n",
    "        collisions.append(collision_rate)\n",
    "        mlflow.log_metric(\"monte_carlo_collision_rate\", collision_rate)\n",
    "\n",
    "        lower, upper = compute_normal_ci(collisions, 0.95)\n",
    "        confidence_ranges.append(upper - lower)\n",
    "        mlflow.log_metric(\"monte_carlo_confidence_interval\", upper - lower)\n",
    "\n",
    "        print(f\"Estimated collision rate from sample distributiion has range: {upper - lower}\")\n",
    "\n",
    "        if len(confidence_ranges) > 100 and np.mean(confidence_ranges[-10:]) >= np.mean(confidence_ranges[-100:]):\n",
    "            return upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "\n",
    "The below sections gives example scenarios to illustrate the working code and validate the proposed approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Base Line*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated collision rate from sample distributiion has range: nan\n",
      "Estimated collision rate from sample distributiion has range: 0.2964781105167489\n",
      "Estimated collision rate from sample distributiion has range: 0.06269862392847415\n",
      "Estimated collision rate from sample distributiion has range: 0.03812545683190424\n",
      "Estimated collision rate from sample distributiion has range: 0.025913487648512788\n",
      "Estimated collision rate from sample distributiion has range: 0.02011545050008124\n",
      "Estimated collision rate from sample distributiion has range: 0.01664232937057071\n",
      "Estimated collision rate from sample distributiion has range: 0.013973435833539702\n",
      "Estimated collision rate from sample distributiion has range: 0.013422851768028713\n",
      "Estimated collision rate from sample distributiion has range: 0.012677651763724838\n",
      "Estimated collision rate from sample distributiion has range: 0.012405935833969352\n",
      "Estimated collision rate from sample distributiion has range: 0.01450084877839957\n",
      "Estimated collision rate from sample distributiion has range: 0.013259832615425723\n",
      "Estimated collision rate from sample distributiion has range: 0.012344963751205789\n",
      "Estimated collision rate from sample distributiion has range: 0.011546165788170509\n",
      "Estimated collision rate from sample distributiion has range: 0.010843115530874279\n",
      "Estimated collision rate from sample distributiion has range: 0.010134964081001216\n",
      "Estimated collision rate from sample distributiion has range: 0.009523288936030806\n",
      "Estimated collision rate from sample distributiion has range: 0.009877897166827219\n",
      "Estimated collision rate from sample distributiion has range: 0.00938079261765407\n",
      "Estimated collision rate from sample distributiion has range: 0.009808767755476164\n",
      "Estimated collision rate from sample distributiion has range: 0.009323873327794205\n",
      "Estimated collision rate from sample distributiion has range: 0.008884717418529586\n",
      "Estimated collision rate from sample distributiion has range: 0.008502860562840879\n",
      "Estimated collision rate from sample distributiion has range: 0.008217285017777201\n",
      "Estimated collision rate from sample distributiion has range: 0.007948715206082188\n",
      "Estimated collision rate from sample distributiion has range: 0.007776591141057582\n",
      "Estimated collision rate from sample distributiion has range: 0.0076403603921869345\n",
      "Estimated collision rate from sample distributiion has range: 0.008050647643084857\n",
      "Estimated collision rate from sample distributiion has range: 0.04044030289735513\n",
      "Estimated collision rate from sample distributiion has range: 0.04195119147664785\n",
      "Estimated collision rate from sample distributiion has range: 0.04144658032193303\n",
      "Estimated collision rate from sample distributiion has range: 0.0411866550551708\n",
      "Estimated collision rate from sample distributiion has range: 0.040585767769648146\n",
      "Estimated collision rate from sample distributiion has range: 0.04002435888014056\n",
      "Estimated collision rate from sample distributiion has range: 0.04068187968684942\n",
      "Estimated collision rate from sample distributiion has range: 0.040143938279272845\n",
      "Estimated collision rate from sample distributiion has range: 0.0396267653925566\n",
      "Estimated collision rate from sample distributiion has range: 0.03923791871417004\n",
      "Estimated collision rate from sample distributiion has range: 0.039799014063159215\n",
      "Estimated collision rate from sample distributiion has range: 0.03940472602488128\n",
      "Estimated collision rate from sample distributiion has range: 0.039076868582364116\n",
      "Estimated collision rate from sample distributiion has range: 0.03918160882496565\n",
      "Estimated collision rate from sample distributiion has range: 0.039405711211662295\n",
      "Estimated collision rate from sample distributiion has range: 0.039500318468134094\n",
      "Estimated collision rate from sample distributiion has range: 0.039408672462460964\n",
      "Estimated collision rate from sample distributiion has range: 0.039006565655810364\n",
      "Estimated collision rate from sample distributiion has range: 0.03860401072378098\n",
      "Estimated collision rate from sample distributiion has range: 0.03851947448286021\n",
      "Estimated collision rate from sample distributiion has range: 0.0383859500952677\n",
      "Estimated collision rate from sample distributiion has range: 0.0380133493527558\n",
      "Estimated collision rate from sample distributiion has range: 0.038123846722418996\n",
      "Estimated collision rate from sample distributiion has range: 0.03806891673159009\n",
      "Estimated collision rate from sample distributiion has range: 0.03773271623475251\n",
      "Estimated collision rate from sample distributiion has range: 0.03815221998255257\n",
      "Estimated collision rate from sample distributiion has range: 0.03787412710646486\n",
      "Estimated collision rate from sample distributiion has range: 0.03760161905390238\n",
      "Estimated collision rate from sample distributiion has range: 0.037824106109637094\n",
      "Estimated collision rate from sample distributiion has range: 0.03761253143959689\n",
      "Estimated collision rate from sample distributiion has range: 0.03740324039432617\n",
      "Estimated collision rate from sample distributiion has range: 0.03750951079731632\n",
      "Estimated collision rate from sample distributiion has range: 0.03722387309621309\n",
      "Estimated collision rate from sample distributiion has range: 0.037030690958372386\n",
      "Estimated collision rate from sample distributiion has range: 0.03680372788529945\n",
      "Estimated collision rate from sample distributiion has range: 0.036997869561025076\n",
      "Estimated collision rate from sample distributiion has range: 0.036781498416897825\n",
      "Estimated collision rate from sample distributiion has range: 0.03652056840029064\n",
      "Estimated collision rate from sample distributiion has range: 0.036342895916021425\n",
      "Estimated collision rate from sample distributiion has range: 0.03787559382201833\n",
      "Estimated collision rate from sample distributiion has range: 0.03784064830182559\n",
      "Estimated collision rate from sample distributiion has range: 0.03762767660494705\n",
      "Estimated collision rate from sample distributiion has range: 0.03741795979981853\n",
      "Estimated collision rate from sample distributiion has range: 0.03725273339818909\n",
      "Estimated collision rate from sample distributiion has range: 0.03733388297657181\n",
      "Estimated collision rate from sample distributiion has range: 0.038646004464692574\n",
      "Estimated collision rate from sample distributiion has range: 0.03852538608797926\n",
      "Estimated collision rate from sample distributiion has range: 0.038295958591332994\n",
      "Estimated collision rate from sample distributiion has range: 0.03817984004484086\n",
      "Estimated collision rate from sample distributiion has range: 0.038170717342597346\n",
      "Estimated collision rate from sample distributiion has range: 0.03795137634637252\n",
      "Estimated collision rate from sample distributiion has range: 0.03799139465946621\n",
      "Estimated collision rate from sample distributiion has range: 0.03775944430483458\n",
      "Estimated collision rate from sample distributiion has range: 0.037652995333574996\n",
      "Estimated collision rate from sample distributiion has range: 0.037450099294425686\n",
      "Estimated collision rate from sample distributiion has range: 0.037324546940621456\n",
      "Estimated collision rate from sample distributiion has range: 0.037107352031081814\n",
      "Estimated collision rate from sample distributiion has range: 0.03778912849462891\n",
      "Estimated collision rate from sample distributiion has range: 0.03765683380276472\n",
      "Estimated collision rate from sample distributiion has range: 0.03744586161549625\n",
      "Estimated collision rate from sample distributiion has range: 0.037432321484403425\n",
      "Estimated collision rate from sample distributiion has range: 0.037227570410867904\n",
      "Estimated collision rate from sample distributiion has range: 0.03703894303381104\n",
      "Estimated collision rate from sample distributiion has range: 0.03702520752509261\n",
      "Estimated collision rate from sample distributiion has range: 0.037007853512689995\n",
      "Estimated collision rate from sample distributiion has range: 0.036824107100319754\n",
      "Estimated collision rate from sample distributiion has range: 0.036956432767798135\n",
      "Estimated collision rate from sample distributiion has range: 0.03721187175753397\n",
      "Estimated collision rate from sample distributiion has range: 0.037937263934457524\n",
      "Estimated collision rate from sample distributiion has range: 0.03791644048383219\n",
      "Estimated collision rate from sample distributiion has range: 0.0380363205959076\n",
      "Estimated collision rate from sample distributiion has range: 0.0381474275196731\n",
      "Upper collision rate: 4.791859824828539%\n",
      "Estimated collision rate from sample distributiion has range: nan\n",
      "Estimated collision rate from sample distributiion has range: 0.21177007894053493\n",
      "Estimated collision rate from sample distributiion has range: 0.04780725255456972\n",
      "Estimated collision rate from sample distributiion has range: 0.027898975361834177\n",
      "Estimated collision rate from sample distributiion has range: 0.018876197026430334\n",
      "Estimated collision rate from sample distributiion has range: 0.014451366249886927\n",
      "Estimated collision rate from sample distributiion has range: 0.012257656412421214\n",
      "Estimated collision rate from sample distributiion has range: 0.010637680859853713\n",
      "Estimated collision rate from sample distributiion has range: 0.009238240166994226\n",
      "Estimated collision rate from sample distributiion has range: 0.00848657962554068\n",
      "Estimated collision rate from sample distributiion has range: 0.007827587768883867\n",
      "Estimated collision rate from sample distributiion has range: 0.007072487296097187\n",
      "Estimated collision rate from sample distributiion has range: 0.0067040394758874355\n",
      "Estimated collision rate from sample distributiion has range: 0.007150175781252922\n",
      "Estimated collision rate from sample distributiion has range: 0.00709689582224881\n",
      "Estimated collision rate from sample distributiion has range: 0.006970343345255755\n",
      "Estimated collision rate from sample distributiion has range: 0.0065327307821362\n",
      "Estimated collision rate from sample distributiion has range: 0.006740646197576989\n",
      "Estimated collision rate from sample distributiion has range: 0.006355604755468532\n",
      "Estimated collision rate from sample distributiion has range: 0.0060229296578007685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# run the experiment 100 times\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     run_experiment(base_part_type, base_part_dim, base_num_samples, base_meta_pdf_ci, base_part_pdf_ci, base_confidence_bound)\n\u001b[1;32m     32\u001b[0m mlflow\u001b[39m.\u001b[39mend_run()\n",
      "Cell \u001b[0;32mIn [14], line 4\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(part_type, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_experiment\u001b[39m(part_type: \u001b[39mstr\u001b[39m, part_dim: \u001b[39mint\u001b[39m, num_samples: \u001b[39mint\u001b[39m, meta_pdf_ci: \u001b[39mfloat\u001b[39m, part_pdf_ci: \u001b[39mfloat\u001b[39m, confidence_bound: \u001b[39mfloat\u001b[39m):\n\u001b[1;32m      3\u001b[0m     con_parts \u001b[39m=\u001b[39m load_part_data(part_type)\n\u001b[0;32m----> 4\u001b[0m     estimated_upper_collision_rate \u001b[39m=\u001b[39m run_meta_markov_multivariant_analysis(\n\u001b[1;32m      5\u001b[0m     con_parts, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpper collision rate: \u001b[39m\u001b[39m{\u001b[39;00mestimated_upper_collision_rate \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [13], line 120\u001b[0m, in \u001b[0;36mrun_meta_markov_multivariant_analysis\u001b[0;34m(parts, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     multivariant_parts \u001b[39m=\u001b[39m limit_deminsionality(parts, \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(part_dim)))\n\u001b[0;32m--> 120\u001b[0m     collision_rate \u001b[39m=\u001b[39m estimate_overlap_of_set_with_sample_signals(multivariant_parts, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n\u001b[1;32m    122\u001b[0m     collisions\u001b[39m.\u001b[39mappend(collision_rate)\n\u001b[1;32m    123\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mmonte_carlo_collision_rate\u001b[39m\u001b[39m\"\u001b[39m, collision_rate)\n",
      "Cell \u001b[0;32mIn [13], line 99\u001b[0m, in \u001b[0;36mestimate_overlap_of_set_with_sample_signals\u001b[0;34m(parts, samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\u001b[0m\n\u001b[1;32m     95\u001b[0m state_space_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultivariate_normal(sample_pdf\u001b[39m.\u001b[39mmean, np\u001b[39m.\u001b[39mdiag(sample_pdf\u001b[39m.\u001b[39mstd), samples)\n\u001b[1;32m     97\u001b[0m \u001b[39m# using probability_of_multivariant_point no longer directly equates to false negative rate.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# TODO (henry): Figure out relationship between integrated pdf range and false negative rate\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m sample_confidences \u001b[39m=\u001b[39m [\n\u001b[1;32m    100\u001b[0m     [probability_of_multivariant_point(pdf\u001b[39m.\u001b[39mmean, np\u001b[39m.\u001b[39mdiag(pdf\u001b[39m.\u001b[39mstd), sample) \u001b[39mfor\u001b[39;00m pdf \u001b[39min\u001b[39;00m part_pdfs]\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m state_space_samples]\n\u001b[1;32m    103\u001b[0m filtered_confidences \u001b[39m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m confidence: confidence \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_confidence, sample_confidence))\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m sample_confidence \u001b[39min\u001b[39;00m sample_confidences]\n\u001b[1;32m    107\u001b[0m \u001b[39m# We're ok with up to 1 match, but every one more than that is a conflict.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [13], line 100\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     95\u001b[0m state_space_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultivariate_normal(sample_pdf\u001b[39m.\u001b[39mmean, np\u001b[39m.\u001b[39mdiag(sample_pdf\u001b[39m.\u001b[39mstd), samples)\n\u001b[1;32m     97\u001b[0m \u001b[39m# using probability_of_multivariant_point no longer directly equates to false negative rate.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# TODO (henry): Figure out relationship between integrated pdf range and false negative rate\u001b[39;00m\n\u001b[1;32m     99\u001b[0m sample_confidences \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 100\u001b[0m     [probability_of_multivariant_point(pdf\u001b[39m.\u001b[39mmean, np\u001b[39m.\u001b[39mdiag(pdf\u001b[39m.\u001b[39mstd), sample) \u001b[39mfor\u001b[39;00m pdf \u001b[39min\u001b[39;00m part_pdfs]\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m state_space_samples]\n\u001b[1;32m    103\u001b[0m filtered_confidences \u001b[39m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m confidence: confidence \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_confidence, sample_confidence))\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m sample_confidence \u001b[39min\u001b[39;00m sample_confidences]\n\u001b[1;32m    107\u001b[0m \u001b[39m# We're ok with up to 1 match, but every one more than that is a conflict.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [13], line 100\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     95\u001b[0m state_space_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultivariate_normal(sample_pdf\u001b[39m.\u001b[39mmean, np\u001b[39m.\u001b[39mdiag(sample_pdf\u001b[39m.\u001b[39mstd), samples)\n\u001b[1;32m     97\u001b[0m \u001b[39m# using probability_of_multivariant_point no longer directly equates to false negative rate.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# TODO (henry): Figure out relationship between integrated pdf range and false negative rate\u001b[39;00m\n\u001b[1;32m     99\u001b[0m sample_confidences \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 100\u001b[0m     [probability_of_multivariant_point(pdf\u001b[39m.\u001b[39;49mmean, np\u001b[39m.\u001b[39;49mdiag(pdf\u001b[39m.\u001b[39;49mstd), sample) \u001b[39mfor\u001b[39;00m pdf \u001b[39min\u001b[39;00m part_pdfs]\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m state_space_samples]\n\u001b[1;32m    103\u001b[0m filtered_confidences \u001b[39m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m confidence: confidence \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_confidence, sample_confidence))\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m sample_confidence \u001b[39min\u001b[39;00m sample_confidences]\n\u001b[1;32m    107\u001b[0m \u001b[39m# We're ok with up to 1 match, but every one more than that is a conflict.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [13], line 78\u001b[0m, in \u001b[0;36mprobability_of_multivariant_point\u001b[0;34m(mu, cov, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprobability_of_multivariant_point\u001b[39m(mu: List[\u001b[39mfloat\u001b[39m], cov: List[List[\u001b[39mfloat\u001b[39m]], x: List[\u001b[39mfloat\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m     \u001b[39m#https://stats.stackexchange.com/questions/331283/how-to-calculate-the-probability-of-a-data-point-belonging-to-a-multivariate-nor\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[39m# Double check this math\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     m_dist_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot((x\u001b[39m-\u001b[39mmu)\u001b[39m.\u001b[39mtranspose(),np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(cov))\n\u001b[1;32m     79\u001b[0m     m_dist_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(m_dist_x, (x\u001b[39m-\u001b[39mmu))\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mstats\u001b[39m.\u001b[39mchi2\u001b[39m.\u001b[39mcdf(m_dist_x, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/site-packages/numpy/linalg/linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    551\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 552\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    553\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(part_type: str, part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "\n",
    "    con_parts = load_part_data(part_type)\n",
    "    estimated_upper_collision_rate = run_meta_markov_multivariant_analysis(\n",
    "    con_parts, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n",
    "    print(f\"Upper collision rate: {estimated_upper_collision_rate * 100}%\")\n",
    "\n",
    "\n",
    "\n",
    "#part_types = [\"BEAM\", \"BOX\", \"BRK\", \"CON\", \"CONLID\", \"FLG\", \"IMP\", \"LID\", \"SEN\", \"TUBE\", \"VNT\"]\n",
    "working_part_types = [\"CON\", \"CONLID\", \"LID\", \"TUBE\"]\n",
    "base_part_dim=5\n",
    "base_num_samples=100\n",
    "base_meta_pdf_ci=0.999\n",
    "base_part_pdf_ci=0.999\n",
    "base_confidence_bound=0.999\n",
    "\n",
    "for base_part_type in working_part_types:\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.log_param(\"part_type\", base_part_type)\n",
    "        mlflow.log_param(\"part_dim\", base_part_dim)\n",
    "        mlflow.log_param(\"num_samples\", base_num_samples)\n",
    "        mlflow.log_param(\"meta_pdf_ci\", base_meta_pdf_ci)\n",
    "        mlflow.log_param(\"part_pdf_ci\", base_part_pdf_ci)\n",
    "        mlflow.log_param(\"confidence_bound\", base_confidence_bound)\n",
    "    \n",
    "        # run the experiment 100 times\n",
    "        for _ in range(100):\n",
    "            run_experiment(base_part_type, base_part_dim, base_num_samples, base_meta_pdf_ci, base_part_pdf_ci, base_confidence_bound)\n",
    "\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cs-6362')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7dd7eb3fce35fa0f50760c8f8b3d129dbc0da5e6df1057aa9ef5bcae08959f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
