{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Part Type Collision Analysis\n",
    "\n",
    "This notebook will contain gathered results from experiment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Type Collision Analysis\n",
    "## Methodology\n",
    "For each part type we have, run the experiment many times over many different hyperparameters. Specifically, isolate one hyperparameter, run the experiment over a range of values, tracking the computed collision rate each time. Repeat this for each hyperparameter and each part type.\n",
    "## Deliverables\n",
    "Graphs and analysis for the impact of different values of the hyperparmeters. How do they affect the final collision rate? Why are the effecting the collision rate like that? What does this tell us? \n",
    "Graphs and analysis for comparing the results across different part types. Are different part types affected in the same way by the same change in hyperperamters? How close are their collision rates? What does this tell us about the relative importance of both hyperparameters and part types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "Installing required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Directory to Parent to allow importing external data files. Please change the specified path based on where this repo exists for you locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/GitHub/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "import dataclasses\n",
    "import mlflow\n",
    "\n",
    "@dataclass\n",
    "class NormalDistribution:\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "@dataclass\n",
    "class Part:\n",
    "\n",
    "    type: str\n",
    "    sub_part_name: str\n",
    "    sensor: str\n",
    "    signals: List   # Signal is numpy array of (500,3) with [frequency, Z, X]\n",
    "\n",
    "\n",
    "def load_part_data(part_type: str) -> List[Part]:\n",
    "\n",
    "    parts = []\n",
    "    for part_dir in os.listdir(f'psig_matcher/data/{part_type}'):\n",
    "\n",
    "        sensor = part_dir[1:]\n",
    "        measurement_files = glob.glob(f'psig_matcher/data/{part_type}/{part_dir}/*.npy')\n",
    "        measurements = [np.load(f) for f in measurement_files]\n",
    "        parts.append(Part(part_type, part_dir, sensor, measurements))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def limit_deminsionality(parts: List[Part], frequeny_indexes: List[int]) -> List[Part]:\n",
    "    \"\"\"Use only a subset of the frequencies for the analysis. This effectivley transforms the\n",
    "    500 dimension multivariant distribution to a n-dimentional distribution where n is the\n",
    "    length of the frequency_indexes.\n",
    "    Further, this assumes use of the X axis\"\"\"\n",
    "\n",
    "    return [\n",
    "        dataclasses.replace(part, signals=[[signal[index][1] for index in frequeny_indexes] for signal in part.signals])\n",
    "        for part in parts]\n",
    "\n",
    "def compute_normal_ci(x: List[float], confidence: float) -> Tuple[float, float]:\n",
    "    \"\"\"Computes the confidence interval for a given confidence bound.\"\"\"\n",
    "\n",
    "    if np.mean(x) == 0: return (0, 0)\n",
    "    \n",
    "    if len(x) < 30:\n",
    "        return st.t.interval(confidence, len(x)-1, loc=np.mean(x), scale=st.sem(x))\n",
    "    else:\n",
    "        return stats.norm.interval(confidence, loc=np.mean(x), scale=np.std(x))\n",
    "\n",
    "def estimate_normal_dist(x: List[float], confidence: float) -> NormalDistribution:\n",
    "    \"\"\"Estimate the normal distribution for the given data.\n",
    "    This is done using: https://handbook-5-1.cochrane.org/chapter_7/7_7_3_2_obtaining_standard_deviations_from_standard_errors_and.htm#:~:text=The%20standard%20deviation%20for%20each,should%20be%20replaced%20by%205.15.\n",
    "    \"\"\"\n",
    "\n",
    "    val_comp = st.t.ppf if len(x) < 30 else stats.norm.ppf\n",
    "    lower, upper = compute_normal_ci(x, confidence)\n",
    "\n",
    "    val = val_comp(confidence, len(x)-1)\n",
    "    std = np.sqrt(len(x))*(upper-lower)*val\n",
    "    return NormalDistribution(np.mean(x, axis=0), std)\n",
    "\n",
    "\n",
    "def probability_of_multivariant_point(mu: List[float], cov: List[List[float]], x: List[float]) -> float:\n",
    "\n",
    "    #https://stats.stackexchange.com/questions/331283/how-to-calculate-the-probability-of-a-data-point-belonging-to-a-multivariate-nor\n",
    "    # Double check this math\n",
    "    m_dist_x = np.dot((x-mu).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mu))\n",
    "    return 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "\n",
    "def estimate_overlap_of_set_with_sample_signals(parts: List[Part], samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float) -> float:\n",
    "    \"\"\" I believe this is the best solution out of all them. We are directly modeling the distribution/state space that\n",
    "    the signals come from, and sampling from that. This directly correlates with the CI and is intuitive. See notion for\n",
    "    more details and defense. \"\"\"\n",
    "\n",
    "    min_confidence = 1 - confidence_bound\n",
    "    signals = [\n",
    "        signal for part in parts\n",
    "        for signal in part.signals]\n",
    "\n",
    "    part_pdfs = [estimate_normal_dist(part.signals, part_pdf_ci) for part in parts]\n",
    "    sample_pdf = estimate_normal_dist(signals, meta_pdf_ci)\n",
    "    \n",
    "    state_space_samples = np.random.multivariate_normal(sample_pdf.mean, np.diag(sample_pdf.std), samples)\n",
    "\n",
    "    # using probability_of_multivariant_point no longer directly equates to false negative rate.\n",
    "    # TODO (henry): Figure out relationship between integrated pdf range and false negative rate\n",
    "    sample_confidences = [\n",
    "        [probability_of_multivariant_point(pdf.mean, np.diag(pdf.std), sample) for pdf in part_pdfs]\n",
    "        for sample in state_space_samples]\n",
    "\n",
    "    filtered_confidences = [\n",
    "        list(filter(lambda confidence: confidence >= min_confidence, sample_confidence))\n",
    "        for sample_confidence in sample_confidences]\n",
    "\n",
    "    # We're ok with up to 1 match, but every one more than that is a conflict.\n",
    "    collisions = [max(len(confidences)-1, 0) for confidences in filtered_confidences]\n",
    "    return sum(collisions)/(samples*len(part_pdfs))\n",
    "\n",
    "def run_meta_markov_multivariant_analysis(parts: List[Part], part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "    \"\"\" Runs the Monte Carlo Approximation of multivariant collision using the signal sample meta\n",
    "    pdf methodology. The Monte Carlo Approximation will continually be run until the confidence interval\n",
    "    converges and the average of the previous 10 runs is not smaller than the average of the previous 100 runs.\"\"\"\n",
    "\n",
    "    collisions = []\n",
    "    confidence_ranges = []\n",
    "    while True:\n",
    "\n",
    "        multivariant_parts = limit_deminsionality(parts, list(range(part_dim)))\n",
    "        collision_rate = estimate_overlap_of_set_with_sample_signals(multivariant_parts, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n",
    "\n",
    "        collisions.append(collision_rate)\n",
    "        mlflow.log_metric(\"monte_carlo_collision_rate\", collision_rate)\n",
    "\n",
    "        lower, upper = compute_normal_ci(collisions, 0.95)\n",
    "        confidence_ranges.append(upper - lower)\n",
    "        mlflow.log_metric(\"monte_carlo_confidence_interval\", upper - lower)\n",
    "\n",
    "        # print(f\"Estimated collision rate from sample distributiion has range: {upper - lower}\")\n",
    "\n",
    "        if len(confidence_ranges) > 100 and np.mean(confidence_ranges[-10:]) >= np.mean(confidence_ranges[-100:]):\n",
    "            return upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "\n",
    "The below sections gives example scenarios to illustrate the working code and validate the proposed approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Base Line*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-104:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "ModuleNotFoundError: No module named 'psig_matcher'\n",
      "Process SpawnPoolWorker-105:\n",
      "Process SpawnPoolWorker-107:\n",
      "Process SpawnPoolWorker-106:\n",
      "Process SpawnPoolWorker-109:\n",
      "Process SpawnPoolWorker-102:\n",
      "Process SpawnPoolWorker-101:\n",
      "Process SpawnPoolWorker-103:\n",
      "Process SpawnPoolWorker-108:\n",
      "Process SpawnPoolWorker-88:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39m#run_parallel_experiment(**params)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pool\u001b[39m.\u001b[39mclose()\n\u001b[0;32m---> 38\u001b[0m pool\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/pool.py:665\u001b[0m, in \u001b[0;36mPool.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (CLOSE, TERMINATE):\n\u001b[1;32m    664\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIn unknown state\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 665\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_worker_handler\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    666\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_handler\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m    667\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_handler\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/cs-6362/lib/python3.10/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import multiprocessing as mp\n",
    "from psig_matcher.experiments import run_experiment\n",
    "\n",
    "import importlib\n",
    "importlib.reload(run_experiment)\n",
    "\n",
    "def run_parallel_experiment(part_type: str, part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "    with mlflow.start_run():\n",
    "        run_experiment.run_experiment(part_type, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n",
    "\n",
    "# param_values = {\n",
    "#     'part_type': [\"CON\"],\n",
    "#     'part_dim' : [1, 5, 10, 50],\n",
    "#     'num_samples': [100],\n",
    "#     'meta_pdf_ci' : [0.5, 0.8, 0.9, 0.95, 0.99, 0.999],\n",
    "#     'part_pdf_ci' : [0.5, 0.8, 0.9, 0.95, 0.99, 0.999],\n",
    "#     'confidence_bound' : [0.5, 0.8, 0.9, 0.95, 0.99, 0.999]}\n",
    "\n",
    "mlflow.set_experiment(\"Experiment 2\")\n",
    "param_values = {\n",
    "    'part_type': [\"CON\"],\n",
    "    'part_dim' : [2],\n",
    "    'num_samples': [1000],\n",
    "    'meta_pdf_ci' : [0.6],\n",
    "    'part_pdf_ci' : [0.5],\n",
    "    'confidence_bound' : [0.5]}\n",
    "\n",
    "parameter_grid = list(ParameterGrid(param_values))\n",
    "print(f\"Running {len(parameter_grid)} experiments\")\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "for params in parameter_grid:\n",
    "    pool.apply_async(run_parallel_experiment, kwds=params)\n",
    "    #run_parallel_experiment(**params)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('matcher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
