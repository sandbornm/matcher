{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Part Signal PDF Convergence\n",
    "\n",
    "This notebook will contain gathered results from experiment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Signal PDF convergence\n",
    "## Methodology \n",
    "For each part we have data for, run the function to simulate the PDF convergence, 100 times. Randomly shuffle the part signals between each run, otherwise it would yeild the same results each time. Track the part, part type, how many signals it needed until convergence, and the relative variance. \n",
    "## Deliverables\n",
    "Associated graphs for each part run showing the the convergence of the CI\n",
    "Graphs and analysis for the combined average of each part type. What does it tell us? What can we conclude about the part type and why it is behaving that way?\n",
    "Graphs and analysis comparing the averages of the different types. How different are they? How can we explain this? Does this validate our assumptions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "Installing required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Directory to Parent to allow importing external data files. Please change the specified path based on where this repo exists for you locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "import dataclasses\n",
    "import argparse\n",
    "import sys\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "@dataclass\n",
    "class NormalDistribution:\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "@dataclass\n",
    "class Part:\n",
    "\n",
    "    type: str\n",
    "    sub_part_name: str\n",
    "    sensor: str\n",
    "    signals: List   # Signal is numpy array of (500,3) with [frequency, Z, X]\n",
    "\n",
    "\n",
    "def load_part_data(part_type: str) -> List[Part]:\n",
    "\n",
    "    parts = []\n",
    "    for part_dir in os.listdir(f'psig_matcher/data/{part_type}'):\n",
    "\n",
    "        sensor = part_dir[1:]\n",
    "        measurement_files = glob.glob(f'psig_matcher/data/{part_type}/{part_dir}/*.npy')\n",
    "        measurements = [np.load(f) for f in measurement_files]\n",
    "        parts.append(Part(part_type, part_dir, sensor, measurements))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def limit_deminsionality(parts: List[Part], frequeny_indexes: List[int]) -> List[Part]:\n",
    "    \"\"\"Use only a subset of the frequencies for the analysis. This effectivley transforms the\n",
    "    500 dimension multivariant distribution to a n-dimentional distribution where n is the\n",
    "    length of the frequency_indexes.\n",
    "    Further, this assumes use of the X axis\"\"\"\n",
    "\n",
    "    return [\n",
    "        dataclasses.replace(part, signals=[[signal[index][1] for index in frequeny_indexes] for signal in part.signals])\n",
    "        for part in parts]\n",
    "\n",
    "def compute_normal_ci(x: List[float], confidence: float) -> Tuple[float, float]:\n",
    "    \"\"\"Computes the confidence interval for a given confidence bound.\"\"\"\n",
    "\n",
    "    if np.mean(x) == 0: return (0, 0)\n",
    "    \n",
    "    if len(x) < 30:\n",
    "        return st.t.interval(confidence, len(x)-1, loc=np.mean(x), scale=st.sem(x))\n",
    "    else:\n",
    "        return stats.norm.interval(confidence, loc=np.mean(x), scale=np.std(x))\n",
    "\n",
    "def estimate_normal_dist(x: List[float], confidence: float) -> NormalDistribution:\n",
    "    \"\"\"Estimate the normal distribution for the given data.\n",
    "    This is done using: https://handbook-5-1.cochrane.org/chapter_7/7_7_3_2_obtaining_standard_deviations_from_standard_errors_and.htm#:~:text=The%20standard%20deviation%20for%20each,should%20be%20replaced%20by%205.15.\n",
    "    \"\"\"\n",
    "\n",
    "    val_comp = st.t.ppf if len(x) < 30 else stats.norm.ppf\n",
    "    lower, upper = compute_normal_ci(x, confidence)\n",
    "\n",
    "    val = val_comp(confidence, len(x)-1)\n",
    "    std = np.sqrt(len(x))*(upper-lower)*val\n",
    "    return NormalDistribution(np.mean(x, axis=0), std)\n",
    "\n",
    "\n",
    "def probability_of_multivariant_point(mu: List[float], cov: List[List[float]], x: List[float]) -> float:\n",
    "\n",
    "    #https://stats.stackexchange.com/questions/331283/how-to-calculate-the-probability-of-a-data-point-belonging-to-a-multivariate-nor\n",
    "    # Double check this math\n",
    "    m_dist_x = np.dot((x-mu).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mu))\n",
    "    return 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "\n",
    "def estimate_overlap_of_set_with_sample_signals(parts: List[Part], samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float) -> float:\n",
    "    \"\"\" I believe this is the best solution out of all them. We are directly modeling the distribution/state space that\n",
    "    the signals come from, and sampling from that. This directly correlates with the CI and is intuitive. See notion for\n",
    "    more details and defense. \"\"\"\n",
    "\n",
    "    min_confidence = 1 - confidence_bound\n",
    "    signals = [\n",
    "        signal for part in parts\n",
    "        for signal in part.signals]\n",
    "\n",
    "    part_pdfs = [estimate_normal_dist(part.signals, part_pdf_ci) for part in parts]\n",
    "    sample_pdf = estimate_normal_dist(signals, meta_pdf_ci)\n",
    "    \n",
    "    state_space_samples = np.random.multivariate_normal(sample_pdf.mean, np.diag(sample_pdf.std), samples)\n",
    "\n",
    "    # using probability_of_multivariant_point no longer directly equates to false negative rate.\n",
    "    # TODO (henry): Figure out relationship between integrated pdf range and false negative rate\n",
    "    sample_confidences = [\n",
    "        [probability_of_multivariant_point(pdf.mean, np.diag(pdf.std), sample) for pdf in part_pdfs]\n",
    "        for sample in state_space_samples]\n",
    "\n",
    "    filtered_confidences = [\n",
    "        list(filter(lambda confidence: confidence >= min_confidence, sample_confidence))\n",
    "        for sample_confidence in sample_confidences]\n",
    "\n",
    "    # We're ok with up to 1 match, but every one more than that is a conflict.\n",
    "    collisions = [max(len(confidences)-1, 0) for confidences in filtered_confidences]\n",
    "    return sum(collisions)/(samples*len(part_pdfs))\n",
    "\n",
    "def run_meta_markov_multivariant_analysis(parts: List[Part], part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "    \"\"\" Runs the Monte Carlo Approximation of multivariant collision using the signal sample meta\n",
    "    pdf methodology. The Monte Carlo Approximation will continually be run until the confidence interval\n",
    "    converges and the average of the previous 10 runs is not smaller than the average of the previous 100 runs.\"\"\"\n",
    "\n",
    "    collisions = []\n",
    "    confidence_ranges = []\n",
    "    while True:\n",
    "\n",
    "        multivariant_parts = limit_deminsionality(parts, list(range(part_dim)))\n",
    "        collision_rate = estimate_overlap_of_set_with_sample_signals(multivariant_parts, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\n",
    "\n",
    "        collisions.append(collision_rate)\n",
    "        mlflow.log_metric(\"monte_carlo_collision_rate\", collision_rate)\n",
    "\n",
    "        lower, upper = compute_normal_ci(collisions, 0.95)\n",
    "        confidence_ranges.append(upper - lower)\n",
    "        mlflow.log_metric(\"monte_carlo_confidence_interval\", upper - lower)\n",
    "\n",
    "        # print(f\"Estimated collision rate from sample distributiion has range: {upper - lower}\")\n",
    "\n",
    "        if len(confidence_ranges) > 100 and np.mean(confidence_ranges[-10:]) >= np.mean(confidence_ranges[-100:]):\n",
    "            return upper\n",
    "\n",
    "def simulate_part_pdf_convergence(part_signals: np.ndarray, part_dim: int, part_pdf_ci: float):\n",
    "    \"\"\" Given a discrete set of signals, this will simulate the part PDF CI convergence methodology.\n",
    "    This function pretend that the set of the signals is infinite, Also incorporate logic to handle\n",
    "    if we didn't converge before we ran out of data. Have modular connection style such that we could\n",
    "    add streaming data source in the future. \"\"\"\n",
    "    sub_samples = []\n",
    "    confidence_ranges = []\n",
    "    while part_signals:\n",
    "        # The below segment is equivalent to sub_samples.append(part_signals.pop())\n",
    "        part_sig = part_signals[0]\n",
    "        part_signals = part_signals[1:]\n",
    "        sub_samples.append(part_sig)\n",
    "        \n",
    "        print(sub_samples)\n",
    "        lower, upper = compute_normal_ci(sub_samples, part_pdf_ci)\n",
    "        print(upper)\n",
    "        print(lower)\n",
    "        confidence_ranges.append(upper - lower)\n",
    "        \n",
    "        mlflow.log_metric(\"part_pdf_confidence_interval\", upper - lower)\n",
    "\n",
    "        if len(confidence_range) > 100 and np.mean(confidence_ranges[-10:]) >= np.mean(confidence_ranges[-100:]):\n",
    "            return upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "\n",
    "The below sections gives example scenarios to illustrate the working code and validate the proposed approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Base Line*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.000000e+04,  1.231336e+03, -1.224784e+03],\n",
      "       [ 1.028100e+04,  1.194632e+03, -1.188328e+03],\n",
      "       [ 1.056100e+04,  1.174042e+03, -1.167742e+03],\n",
      "       ...,\n",
      "       [ 1.494400e+05,  1.353826e+02, -1.316107e+02],\n",
      "       [ 1.497200e+05,  1.339316e+02, -1.303323e+02],\n",
      "       [ 1.500000e+05,  1.325994e+02, -1.291248e+02]])]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to convert metric value to float: can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\metric_value_conversion_utils.py:12\u001b[0m, in \u001b[0;36m_try_get_item\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart_pdf_ci\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_part_pdf_ci)\n\u001b[0;32m     23\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_confidence_bound)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_part_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_part_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_num_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_meta_pdf_ci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_part_pdf_ci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_confidence_bound\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(part_type, part_dim, num_samples, meta_pdf_ci, part_pdf_ci, confidence_bound)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m con_part \u001b[38;5;129;01min\u001b[39;00m con_parts:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m con_part\u001b[38;5;241m.\u001b[39msignals:\n\u001b[1;32m----> 6\u001b[0m         upper_collision_rate \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_part_pdf_convergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_part\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_pdf_ci\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper collision rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper_collision_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 154\u001b[0m, in \u001b[0;36msimulate_part_pdf_convergence\u001b[1;34m(part_signals, part_dim, part_pdf_ci)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(lower)\n\u001b[0;32m    152\u001b[0m confidence_ranges\u001b[38;5;241m.\u001b[39mappend(upper \u001b[38;5;241m-\u001b[39m lower)\n\u001b[1;32m--> 154\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpart_pdf_confidence_interval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(confidence_range) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(confidence_ranges[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(confidence_ranges[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:]):\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m upper\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:644\u001b[0m, in \u001b[0;36mlog_metric\u001b[1;34m(key, value, step)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03mLog a metric under the current run. If no run is active, this method will create\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03ma new active run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m        mlflow.log_metric(\"mse\", 2500.00)\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    643\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m--> 644\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\client.py:821\u001b[0m, in \u001b[0;36mMlflowClient.log_metric\u001b[1;34m(self, run_id, key, value, timestamp, step)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_metric\u001b[39m(\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    760\u001b[0m     run_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    764\u001b[0m     step: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    765\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03m    Log a metric against the run ID.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m        status: FINISHED\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:305\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_metric\u001b[1;34m(self, run_id, key, value, timestamp, step)\u001b[0m\n\u001b[0;32m    303\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m timestamp \u001b[38;5;28;01mif\u001b[39;00m timestamp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m get_current_time_millis()\n\u001b[0;32m    304\u001b[0m step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 305\u001b[0m metric_value \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_metric_value_to_float_if_possible\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m metric \u001b[38;5;241m=\u001b[39m Metric(key, metric_value, timestamp, step)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_metric(run_id, metric)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\metric_value_conversion_utils.py:47\u001b[0m, in \u001b[0;36mconvert_metric_value_to_float_if_possible\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     40\u001b[0m converter_fns_to_try \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     41\u001b[0m     convert_metric_value_to_float_if_ndarray,\n\u001b[0;32m     42\u001b[0m     convert_metric_value_to_float_if_tensorflow_tensor,\n\u001b[0;32m     43\u001b[0m     convert_metric_value_to_float_if_torch_tensor,\n\u001b[0;32m     44\u001b[0m ]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m converter_fn \u001b[38;5;129;01min\u001b[39;00m converter_fns_to_try:\n\u001b[1;32m---> 47\u001b[0m     possible_float \u001b[38;5;241m=\u001b[39m \u001b[43mconverter_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(possible_float) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m possible_float\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\metric_value_conversion_utils.py:29\u001b[0m, in \u001b[0;36m_converter_requires.<locals>.decorator.<locals>.wrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_module_imported(module_name):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\metric_value_conversion_utils.py:62\u001b[0m, in \u001b[0;36mconvert_metric_value_to_float_if_ndarray\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43m_try_get_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\tracking\\metric_value_conversion_utils.py:14\u001b[0m, in \u001b[0;36m_try_get_item\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert metric value to float: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     17\u001b[0m     )\n",
      "\u001b[1;31mMlflowException\u001b[0m: Failed to convert metric value to float: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "def run_experiment(part_type: str, part_dim: int, num_samples: int, meta_pdf_ci: float, part_pdf_ci: float, confidence_bound: float):\n",
    "\n",
    "    con_parts = load_part_data(part_type)\n",
    "    for con_part in con_parts:\n",
    "        for signal in con_part.signals:\n",
    "            upper_collision_rate = simulate_part_pdf_convergence(con_part.signals, part_dim, part_pdf_ci)\n",
    "            print(f\"Upper collision rate: {upper_collision_rate * 100}%\")\n",
    "\n",
    "mlflow.end_run()\n",
    "with mlflow.start_run():\n",
    "    base_part_type=\"CON\"\n",
    "    base_part_dim=5\n",
    "    base_num_samples=100\n",
    "    base_meta_pdf_ci=0.999\n",
    "    base_part_pdf_ci=0.999\n",
    "    base_confidence_bound=0.999\n",
    "\n",
    "    mlflow.log_param(\"part_type\", base_part_type)\n",
    "    mlflow.log_param(\"part_dim\", base_part_dim)\n",
    "    mlflow.log_param(\"num_samples\", base_num_samples)\n",
    "    mlflow.log_param(\"meta_pdf_ci\", base_meta_pdf_ci)\n",
    "    mlflow.log_param(\"part_pdf_ci\", base_part_pdf_ci)\n",
    "    mlflow.log_param(\"confidence_bound\", base_confidence_bound)\n",
    "\n",
    "    run_experiment(base_part_type, base_part_dim, base_num_samples, base_meta_pdf_ci, base_part_pdf_ci, base_confidence_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
