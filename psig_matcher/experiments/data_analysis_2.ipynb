{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Part Type Collision Analysis\n",
    "\n",
    "This notebook will contain gathered results from experiment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Type Collision Analysis\n",
    "## Methodology\n",
    "For each part type we have, run the experiment many times over many different hyperparameters. Specifically, isolate one hyperparameter, run the experiment over a range of values, tracking the computed collision rate each time. Repeat this for each hyperparameter and each part type.\n",
    "## Deliverables\n",
    "Graphs and analysis for the impact of different values of the hyperparmeters. How do they affect the final collision rate? Why are the effecting the collision rate like that? What does this tell us? \n",
    "Graphs and analysis for comparing the results across different part types. Are different part types affected in the same way by the same change in hyperperamters? How close are their collision rates? What does this tell us about the relative importance of both hyperparameters and part types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.client.MlflowClient()\n",
    "experiment_id = mlflow_client.get_experiment_by_name(\"Experiment 2\").experiment_id\n",
    "print(experiment_id)\n",
    "runs = mlflow_client.search_runs(experiment_id, max_results=10_000)\n",
    "print(len(runs))\n",
    "\n",
    "run_dicts = {\n",
    "    run.info.run_id: {\n",
    "        **run.data.metrics, \n",
    "        **run.data.params}\n",
    "    for run in runs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = pd.DataFrame.from_dict(run_dicts, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_groups = {\n",
    "    \"part_dim\": run_df.groupby('part_dim'),\n",
    "    \"confidence_bound\": run_df.groupby('confidence_bound'),\n",
    "    \"part_pdf_ci\": run_df.groupby('part_pdf_ci'),\n",
    "    \"meta_pdf_ci\": run_df.groupby('meta_pdf_ci')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_experiment(\"Experiment 2 Analysis\")\n",
    "for analysis_type in analysis_groups:\n",
    "   \n",
    "    group = analysis_groups[analysis_type]\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    \n",
    "    for df in group:\n",
    "        \n",
    "        col_vals = set(df[analysis_type].to_list())\n",
    "        if len(x_vals) != 1:\n",
    "            raise Exception(f\"More than one {analysis_type} value in group\")\n",
    "        \n",
    "        x_vals.append(col_vals.pop())\n",
    "        y_vals.append(df['upper_collision_rate'].mean())\n",
    "        \n",
    "    plt.plot(x_vals, y_vals, label=f'{analysis_type}s vs upper_collision_rate')\n",
    "    plt.xlabel(analysis_type)\n",
    "    plt.ylabel(f\"Averaged upper_collision_rate across all tested parts\")\n",
    "    plt.savefig(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    mlflow.log_artifact(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('matcher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
