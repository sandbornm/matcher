{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Part Type Collision Analysis\n",
    "\n",
    "This notebook will contain gathered results from experiment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Type Collision Analysis\n",
    "## Methodology\n",
    "For each part type we have, run the experiment many times over many different hyperparameters. Specifically, isolate one hyperparameter, run the experiment over a range of values, tracking the computed collision rate each time. Repeat this for each hyperparameter and each part type.\n",
    "## Deliverables\n",
    "Graphs and analysis for the impact of different values of the hyperparmeters. How do they affect the final collision rate? Why are the effecting the collision rate like that? What does this tell us? \n",
    "Graphs and analysis for comparing the results across different part types. Are different part types affected in the same way by the same change in hyperperamters? How close are their collision rates? What does this tell us about the relative importance of both hyperparameters and part types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = mlflow.client.MlflowClient()\n",
    "experiment_id = mlflow_client.get_experiment_by_name(\"Experiment 2\").experiment_id\n",
    "print(experiment_id)\n",
    "runs = mlflow_client.search_runs(experiment_id, max_results=10_000)\n",
    "# print(len(runs))\n",
    "\n",
    "run_dicts = {\n",
    "    run.info.run_id: {\n",
    "        **run.data.metrics, \n",
    "        **run.data.params}\n",
    "    for run in runs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['part_dim', 'confidence_bound', 'part_pdf_ci', 'meta_pdf_ci',\n",
      "       'num_samples', 'part_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "run_df = pd.DataFrame.from_dict(run_dicts, orient='index')\n",
    "print(run_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_groups = {\n",
    "    \"part_dim\": run_df.groupby('part_dim'),\n",
    "    \"confidence_bound\": run_df.groupby('confidence_bound'),\n",
    "    \"part_pdf_ci\": run_df.groupby('part_pdf_ci'),\n",
    "    \"meta_pdf_ci\": run_df.groupby('meta_pdf_ci')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'upper_collision_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'upper_collision_rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMore than one \u001b[39m\u001b[39m{\u001b[39;00manalysis_type\u001b[39m}\u001b[39;00m\u001b[39m value in group\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     x_vals\u001b[39m.\u001b[39mappend(col_vals\u001b[39m.\u001b[39mpop())\n\u001b[0;32m---> 15\u001b[0m     y_vals\u001b[39m.\u001b[39mappend(df[\u001b[39m'\u001b[39;49m\u001b[39mupper_collision_rate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     17\u001b[0m plt\u001b[39m.\u001b[39mplot(x_vals, y_vals, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00manalysis_type\u001b[39m}\u001b[39;00m\u001b[39ms vs upper_collision_rate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39mxlabel(analysis_type)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'upper_collision_rate'"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Experiment 2 Analysis\")\n",
    "for analysis_type in analysis_groups:\n",
    "   \n",
    "    group = analysis_groups[analysis_type]\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    \n",
    "    for index, df in group:\n",
    "\n",
    "        col_vals = set(df[analysis_type].to_list())\n",
    "        if len(col_vals) != 1:\n",
    "            raise Exception(f\"More than one {analysis_type} value in group\")\n",
    "        \n",
    "        x_vals.append(col_vals.pop())\n",
    "        y_vals.append(df['upper_collision_rate'].mean())\n",
    "        \n",
    "    plt.plot(x_vals, y_vals, label=f'{analysis_type}s vs upper_collision_rate')\n",
    "    plt.xlabel(analysis_type)\n",
    "    plt.ylabel(f\"Averaged upper_collision_rate across all tested parts\")\n",
    "    plt.savefig(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    mlflow.log_artifact(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
