{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Part Type Collision Analysis\n",
    "\n",
    "This notebook will contain gathered results from experiment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Type Collision Analysis\n",
    "## Methodology\n",
    "For each part type we have, run the experiment many times over many different hyperparameters. Specifically, isolate one hyperparameter, run the experiment over a range of values, tracking the computed collision rate each time. Repeat this for each hyperparameter and each part type.\n",
    "## Deliverables\n",
    "Graphs and analysis for the impact of different values of the hyperparmeters. How do they affect the final collision rate? Why are the effecting the collision rate like that? What does this tell us? \n",
    "Graphs and analysis for comparing the results across different part types. Are different part types affected in the same way by the same change in hyperperamters? How close are their collision rates? What does this tell us about the relative importance of both hyperparameters and part types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/GitHub/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_series(mlruns_path: str, experiment_id: str, run_id: str, metric_name: str) -> list:\n",
    "    \"\"\"Get a series of metric values for a given metric name.\"\"\"\n",
    "    with open(f'{mlruns_path}/{experiment_id}/{run_id}/metrics/{metric_name}') as f:\n",
    "        file_lines = f.readlines()\n",
    "    return [float(line.split()[1]) for line in file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '526822730466242966'. Detailed error Yaml file '/Users/henrygilbert/GitHub/matcher/mlruns/526822730466242966/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 279, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 372, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1082, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1075, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 182, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/henrygilbert/GitHub/matcher/mlruns/526822730466242966/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0.2758493175418901, 0.2686923494918686, 0.274...\n",
      "Name: monte_carlo_upper_collision_rate_series, dtype: object\n",
      "0    6874a8cf8aa54bb5b3ffdad4de91fc8c\n",
      "Name: run_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(name='Experiment 3').experiment_id\n",
    "runs_df = mlflow.search_runs(experiment_ids=experiment_id, max_results=10_000)\n",
    "runs_df['monte_carlo_upper_collision_rate_series'] = runs_df.apply(\n",
    "    lambda row: get_metrics_series(\n",
    "            mlruns_path='mlruns', \n",
    "            experiment_id=experiment_id, \n",
    "            run_id=row['run_id'], \n",
    "            metric_name='monte_carlo_upper_collision_rate'), \n",
    "    axis=1)\n",
    "\n",
    "print(runs_df.head(1)['monte_carlo_upper_collision_rate_series'])\n",
    "print(runs_df.head(1)['run_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['monte_carlo_upper_collision_rate', 'part_dim', 'confidence_bound',\n",
      "       'part_pdf_ci', 'meta_pdf_ci', 'num_samples', 'part_type'],\n",
      "      dtype='object')\n",
      "                                  monte_carlo_upper_collision_rate part_dim  \\\n",
      "6874a8cf8aa54bb5b3ffdad4de91fc8c                          0.285976        2   \n",
      "\n",
      "                                 confidence_bound part_pdf_ci meta_pdf_ci  \\\n",
      "6874a8cf8aa54bb5b3ffdad4de91fc8c            0.999      0.9999       0.995   \n",
      "\n",
      "                                 num_samples  part_type  \n",
      "6874a8cf8aa54bb5b3ffdad4de91fc8c         100  CONTAINER  \n"
     ]
    }
   ],
   "source": [
    "run_df = pd.DataFrame.from_dict(run_dicts, orient='index')\n",
    "print(run_df.columns)\n",
    "print(run_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_groups = {\n",
    "    \"part_dim\": run_df.groupby('part_dim'),\n",
    "    \"confidence_bound\": run_df.groupby('confidence_bound'),\n",
    "    \"part_pdf_ci\": run_df.groupby('part_pdf_ci'),\n",
    "    \"meta_pdf_ci\": run_df.groupby('meta_pdf_ci')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'upper_collision_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'upper_collision_rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMore than one \u001b[39m\u001b[39m{\u001b[39;00manalysis_type\u001b[39m}\u001b[39;00m\u001b[39m value in group\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     x_vals\u001b[39m.\u001b[39mappend(col_vals\u001b[39m.\u001b[39mpop())\n\u001b[0;32m---> 15\u001b[0m     y_vals\u001b[39m.\u001b[39mappend(df[\u001b[39m'\u001b[39;49m\u001b[39mupper_collision_rate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     17\u001b[0m plt\u001b[39m.\u001b[39mplot(x_vals, y_vals, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00manalysis_type\u001b[39m}\u001b[39;00m\u001b[39ms vs upper_collision_rate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39mxlabel(analysis_type)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/matcher/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'upper_collision_rate'"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Experiment 2 Analysis\")\n",
    "for analysis_type in analysis_groups:\n",
    "   \n",
    "    group = analysis_groups[analysis_type]\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    \n",
    "    for index, df in group:\n",
    "\n",
    "        col_vals = set(df[analysis_type].to_list())\n",
    "        if len(col_vals) != 1:\n",
    "            raise Exception(f\"More than one {analysis_type} value in group\")\n",
    "        \n",
    "        x_vals.append(col_vals.pop())\n",
    "        y_vals.append(df['upper_collision_rate'].mean())\n",
    "        \n",
    "    plt.plot(x_vals, y_vals, label=f'{analysis_type}s vs upper_collision_rate')\n",
    "    plt.xlabel(analysis_type)\n",
    "    plt.ylabel(f\"Averaged upper_collision_rate across all tested parts\")\n",
    "    plt.savefig(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    mlflow.log_artifact(f\"psig_matcher/experiments/graphs/{analysis_type}_vs_upper_collision_rate.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
