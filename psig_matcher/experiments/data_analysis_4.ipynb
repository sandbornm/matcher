{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/GitHub/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_series(mlruns_path: str, experiment_id: str, run_id: str, metric_name: str) -> list:\n",
    "    \"\"\"Get a series of metric values for a given metric name.\"\"\"\n",
    "    with open(f'{mlruns_path}/{experiment_id}/{run_id}/metrics/{metric_name}') as f:\n",
    "        file_lines = f.readlines()\n",
    "    return [float(line.split()[1]) for line in file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(name='Experiment 3 - test').experiment_id\n",
    "runs_df = mlflow.search_runs(experiment_ids=experiment_id, max_results=10_000)\n",
    "\n",
    "runs_df['params.part_dim'] = runs_df['params.part_dim'].astype(float)\n",
    "runs_df['metrics.monte_carlo_upper_collision_rate'] = runs_df['metrics.monte_carlo_upper_collision_rate'].astype(float)\n",
    "runs_df['params.part_pdf_ci'] = runs_df['params.part_pdf_ci'].astype(float)\n",
    "runs_df['params.confidence_bound'] = runs_df['params.confidence_bound'].astype(float)\n",
    "runs_df['params.meta_pdf_ci'] = runs_df['params.meta_pdf_ci'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "part_dim = [2, 3, 5]\n",
    "meta_pdf_ci = [0.95, 0.99, 0.999]\n",
    "part_pdf_ci = [0.95, 0.99, 0.999]\n",
    "confidence_bound = [0.95, 0.99, 0.999, 0.9999]\n",
    "\n",
    "base_meta_pdf_ci = 0.99\n",
    "base_part_pdf_ci = 0.99\n",
    "base_confidence_bound = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Experiment 2 Analysis - 2')\n",
    "mlflow.end_run()\n",
    "mlflow.start_run()\n",
    "\n",
    "part_dim_analysis_df = runs_df.loc[\n",
    "    (runs_df['params.meta_pdf_ci'] == base_meta_pdf_ci) &\n",
    "    (runs_df['params.part_pdf_ci'] == base_part_pdf_ci) &\n",
    "    (runs_df['params.confidence_bound'] == base_confidence_bound)]\n",
    "\n",
    "\n",
    "part_dim_part_groups = part_dim_analysis_df.groupby('params.part_type')\n",
    "def run_experiment(df_groups, param_col: str):\n",
    "    \n",
    "    for part_type, part_group in df_groups:\n",
    "        part_group.sort_values(by=param_col, inplace=True)\n",
    "        collision_rate = part_group['metrics.monte_carlo_upper_collision_rate'].to_numpy()\n",
    "        plt.plot(part_group[param_col], collision_rate, label=f'{part_type} - Correlation: {np.corrcoef(part_group[param_col], collision_rate)[0,1]:.2f}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(f'Estimated Upper Collision Rate vs {param_col}')\n",
    "    plt.xlabel(f'{param_col}')\n",
    "    plt.ylabel('Estimated Upper Collision Rate')\n",
    "    plt.savefig(f'psig_matcher/experiments/graphs/collision_rate_vs_{param_col}.png')\n",
    "    mlflow.log_artifact(f'psig_matcher/experiments/graphs/collision_rate_vs_{param_col}.png')\n",
    "    plt.clf()\n",
    "        \n",
    "run_experiment(part_dim_part_groups, 'params.part_dim')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def run_part_type_averaged_experiment(df_groups, param_col: str):\n",
    "    \n",
    "    y_vals = []\n",
    "    for _, part_group in df_groups:\n",
    "        \n",
    "        part_group.sort_values(by=param_col, inplace=True)\n",
    "        y_vals.append(part_group['metrics.monte_carlo_upper_collision_rate'].to_numpy())\n",
    "        \n",
    "    averaged_y_vals = np.mean(y_vals, axis=0)    \n",
    "    plt.plot(part_group[param_col], averaged_y_vals, label=f'Averaged Across Part Types - Correlation: {np.corrcoef(part_group[param_col], averaged_y_vals)[0,1]:.2f}')\n",
    "    plt.legend()\n",
    "    plt.title(f'Estimated Upper Collision Rate vs {param_col}')\n",
    "    plt.xlabel(f'{param_col}')\n",
    "    plt.ylabel('Estimated Upper Collision Rate')\n",
    "    plt.savefig(f'psig_matcher/experiments/graphs/averaged_collision_rate_vs_{param_col}.png')\n",
    "    mlflow.log_artifact(f'psig_matcher/experiments/graphs/averaged_collision_rate_vs_{param_col}.png')\n",
    "    plt.clf()\n",
    "    \n",
    "run_part_type_averaged_experiment(part_dim_part_groups, 'params.part_dim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
