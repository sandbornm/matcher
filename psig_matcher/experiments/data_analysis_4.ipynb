{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Part Type Collision Analysis\n",
    "\n",
    "This notebook will contain gathered results from experiment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Type Collision Analysis\n",
    "## Methodology\n",
    "For each part type we have, run the experiment many times over many different hyperparameters. Specifically, isolate one hyperparameter, run the experiment over a range of values, tracking the computed collision rate each time. Repeat this for each hyperparameter and each part type.\n",
    "## Deliverables\n",
    "Graphs and analysis for the impact of different values of the hyperparmeters. How do they affect the final collision rate? Why are the effecting the collision rate like that? What does this tell us? \n",
    "Graphs and analysis for comparing the results across different part types. Are different part types affected in the same way by the same change in hyperperamters? How close are their collision rates? What does this tell us about the relative importance of both hyperparameters and part types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "The below sections contains all of our source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "user_path = '~/GitHub/matcher'  # CHANGE THIS LINE AS NEEDED FOR YOUR ENVIRONMENT\n",
    "os.chdir(os.path.expanduser(user_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_series(mlruns_path: str, experiment_id: str, run_id: str, metric_name: str) -> list:\n",
    "    \"\"\"Get a series of metric values for a given metric name.\"\"\"\n",
    "    with open(f'{mlruns_path}/{experiment_id}/{run_id}/metrics/{metric_name}') as f:\n",
    "        file_lines = f.readlines()\n",
    "    return [float(line.split()[1]) for line in file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(name='Experiment 4').experiment_id\n",
    "runs_df = mlflow.search_runs(experiment_ids=experiment_id, max_results=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_meta_pdf_ci = 0.995\n",
    "base_part_pdf_ci = 0.995\n",
    "base_confidence_bound = 0.995\n",
    "part_dim_base = 2\n",
    "\n",
    "runs_df['params.part_dim'] = runs_df['params.part_dim'].astype(float)\n",
    "runs_df['metrics.average_part_pdf_entropy'] = runs_df['metrics.average_part_pdf_entropy'].astype(float)\n",
    "runs_df['params.part_pdf_ci'] = runs_df['params.part_pdf_ci'].astype(float)\n",
    "runs_df['params.confidence_bound'] = runs_df['params.confidence_bound'].astype(float)\n",
    "runs_df['params.meta_pdf_ci'] = runs_df['params.meta_pdf_ci'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Experiment 4 Analysis')\n",
    "mlflow.end_run()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "part_pdf_ci_analysis_df = runs_df.loc[\n",
    "    (runs_df['params.confidence_bound'] == base_confidence_bound) &\n",
    "    (runs_df['params.meta_pdf_ci'] == base_meta_pdf_ci)&\n",
    "    (runs_df['params.part_dim'] == part_dim_base)]\n",
    "part_dim_analysis_df = runs_df.loc[\n",
    "    (runs_df['params.meta_pdf_ci'] == base_meta_pdf_ci) &\n",
    "    (runs_df['params.part_pdf_ci'] == base_part_pdf_ci) &\n",
    "    (runs_df['params.confidence_bound'] == base_confidence_bound)]\n",
    "\n",
    "part_pdf_ci_part_groups = part_pdf_ci_analysis_df.groupby('params.part_type')\n",
    "part_dim_part_groups = part_dim_analysis_df.groupby('params.part_type')\n",
    "\n",
    "def run_experiment(df_groups, param_col: str):\n",
    "    \n",
    "    for part_type, part_group in df_groups:\n",
    "        \n",
    "        print(part_group['metrics.average_part_pdf_entropy'])\n",
    "        part_group.sort_values(by=param_col, inplace=True)\n",
    "        average_entropys = part_group['metrics.average_part_pdf_entropy'].to_numpy()\n",
    "        plt.plot(part_group[param_col], average_entropys, label=f'{part_type} - Correlation: {np.corrcoef(part_group[param_col], average_entropys)[0,1]:.2f}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(f'Entropy of System vs {param_col}')\n",
    "    plt.xlabel(f'{param_col}')\n",
    "    plt.ylabel('Entropy of System')\n",
    "    plt.savefig(f'psig_matcher/experiments/graphs/entropy_of_system_vs_{param_col}.png')\n",
    "    mlflow.log_artifact(f'psig_matcher/experiments/graphs/entropy_of_system_vs_{param_col}.png')\n",
    "    plt.clf()\n",
    "        \n",
    "run_experiment(part_dim_part_groups, 'params.part_dim')\n",
    "run_experiment(part_pdf_ci_part_groups, 'params.part_pdf_ci')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def run_part_type_averaged_experiment(df_groups, param_col: str):\n",
    "    \n",
    "    y_vals = []\n",
    "    for _, part_group in df_groups:\n",
    "        \n",
    "        part_group.sort_values(by=param_col, inplace=True)\n",
    "        y_vals.append(part_group['metrics.average_part_pdf_entropy'].to_numpy())\n",
    "        \n",
    "    averaged_y_vals = np.mean(y_vals, axis=0)    \n",
    "    plt.plot(part_group[param_col], averaged_y_vals, label=f'Averaged Across Part Types - Correlation: {np.corrcoef(part_group[param_col], averaged_y_vals)[0,1]:.2f}')\n",
    "    plt.legend()\n",
    "    plt.title(f'Entropy of System vs {param_col}')\n",
    "    plt.xlabel(f'{param_col}')\n",
    "    plt.ylabel('Entropy of System')\n",
    "    plt.savefig(f'psig_matcher/experiments/graphs/averaged_entropy_of_system_vs_{param_col}.png')\n",
    "    mlflow.log_artifact(f'psig_matcher/experiments/graphs/averaged_entropy_of_system_vs_{param_col}.png')\n",
    "    plt.clf()\n",
    "    \n",
    "run_part_type_averaged_experiment(part_dim_part_groups, 'params.part_dim')\n",
    "run_part_type_averaged_experiment(part_pdf_ci_part_groups, 'params.part_pdf_ci')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e408d6d2624d2574650b7f4ce724a272157838fb62dd59ce9f909f9eb3ba3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
